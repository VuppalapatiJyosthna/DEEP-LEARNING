{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Alexnet.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN502NT2EwWlW3HAFCeaxaH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VuppalapatiJyosthna/DEEP-LEARNING/blob/main/Alexnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXqDkDUFo7zt"
      },
      "source": [
        "20MAI0058\n",
        "GITHUB LINK:"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEcZ4t02i7yo"
      },
      "source": [
        "#Importing library\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(1000)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wi7F5g2jHAY"
      },
      "source": [
        "\n",
        "#Instantiation\n",
        "AlexNet = Sequential()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZ21EF0sjJ6u"
      },
      "source": [
        "#1st Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=96, input_shape=(32,32,3), kernel_size=(11,11), strides=(4,4), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N5chtxUjPJB"
      },
      "source": [
        "#2nd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02WZHnjAjRbI"
      },
      "source": [
        "#3rd Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTDsFMVJjtET"
      },
      "source": [
        "#4th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKhMMx8Njvp5"
      },
      "source": [
        "#5th Convolutional Layer\n",
        "AlexNet.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))\n",
        "AlexNet.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx-DJhL4kGMq"
      },
      "source": [
        "#Passing it to a Fully Connected layer\n",
        "AlexNet.add(Flatten())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdNhdoRYkKkq"
      },
      "source": [
        "# 1st Fully Connected Layer\n",
        "AlexNet.add(Dense(4096, input_shape=(32,32,3,)))\n",
        "AlexNet.add(BatchNormalization())\n",
        "AlexNet.add(Activation('relu'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVhrpcNwkO-Z"
      },
      "source": [
        "# Add Dropout to prevent overfitting\n",
        "AlexNet.add(Dropout(0.4))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQRIqrPPkR5Y",
        "outputId": "f3e1d2b5-474e-4075-a73d-35a32dbcdfd6"
      },
      "source": [
        "#Model Summary\n",
        "AlexNet.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 8, 8, 96)          34944     \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 8, 8, 96)          384       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 4, 4, 256)         614656    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4, 4, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 4, 4, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 2, 2, 256)         1638656   \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 2, 2, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 1, 1, 384)         885120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 1, 1, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1, 1, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 1, 1, 384)         1327488   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1, 1, 384)         1536      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 1, 1, 384)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 1, 1, 256)         884992    \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 1, 1, 256)         590080    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 1, 1, 256)         1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 4096)              1052672   \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 4096)              16384     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 4096)              0         \n",
            "=================================================================\n",
            "Total params: 23,850,240\n",
            "Trainable params: 23,830,080\n",
            "Non-trainable params: 20,160\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmhyS5banIYU"
      },
      "source": [
        "# Compiling the model\n",
        "AlexNet.compile(loss = keras.losses.categorical_crossentropy, optimizer= 'adam', metrics=['accuracy'])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0EO6JHhndaZ",
        "outputId": "536c0aed-be01-4343-bfb5-d7aa61a9224e"
      },
      "source": [
        "#Keras library for CIFAR dataset\n",
        "from keras.datasets import cifar10\n",
        "(x_train, y_train),(x_test, y_test)=cifar10.load_data()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M9mAyfGnszz"
      },
      "source": [
        "\n",
        "#Train-validation-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Poqq-RFCnwxX",
        "outputId": "c6e1fcef-56b3-4364-a527-450abe5fc81e"
      },
      "source": [
        "\n",
        "#Dimension of the CIFAR10 dataset\n",
        "print((x_train.shape,y_train.shape))\n",
        "print((x_val.shape,y_val.shape))\n",
        "print((x_test.shape,y_test.shape))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((35000, 32, 32, 3), (35000, 1))\n",
            "((15000, 32, 32, 3), (15000, 1))\n",
            "((10000, 32, 32, 3), (10000, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UDh3s59oCCP"
      },
      "source": [
        "\n",
        "#Image Data Augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1 )\n",
        "\n",
        "val_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
        "\n",
        "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
        "\n",
        "#Fitting the augmentation defined above to the data\n",
        "train_generator.fit(x_train)\n",
        "val_generator.fit(x_val)\n",
        "test_generator.fit(x_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ekXabhuoE-0"
      },
      "source": [
        "#Learning Rate Annealer\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lrr= ReduceLROnPlateau(   monitor='val_acc',   factor=.01,   patience=3,  min_lr=1e-5) "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNEbarrHoJsw"
      },
      "source": [
        "#Defining the parameters\n",
        "batch_size= 100\n",
        "epochs=10\n",
        "learn_rate=.001"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS-roM6doPF0",
        "outputId": "1562b736-515e-44ae-93fe-2af75686547c"
      },
      "source": [
        "#Training the model\n",
        "AlexNet.fit_generator(train_generator.flow(x_train, y_train, batch_size=batch_size), epochs = epochs, steps_per_epoch = x_train.shape[0]//batch_size, validation_data = val_generator.flow(x_val, y_val, batch_size=batch_size), validation_steps = 250, callbacks = [lrr], verbose=1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "349/350 [============================>.] - ETA: 0s - loss: nan - accuracy: 1.7843e-05WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 250 batches). You may need to use the repeat() function when building your dataset.\n",
            "350/350 [==============================] - 56s 63ms/step - loss: nan - accuracy: 1.7904e-05 - val_loss: 153332.9062 - val_accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n",
            "Epoch 2/10\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 205762.1650 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 3/10\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 205840.0886 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 4/10\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 204884.8820 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 5/10\n",
            "350/350 [==============================] - 16s 45ms/step - loss: 205296.8498 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 6/10\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 206951.4789 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 7/10\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 205243.9899 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 8/10\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 204615.3869 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 9/10\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 204374.1065 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n",
            "Epoch 10/10\n",
            "350/350 [==============================] - 16s 46ms/step - loss: 205927.3836 - accuracy: 0.0000e+00\n",
            "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f8e360758d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJYyer0Goh5b"
      },
      "source": [
        "\n",
        "#After successful training, we will visualize its performance.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "#Plotting the training and validation loss\n",
        "\n",
        "f,ax=plt.subplots(2,1) #Creates 2 subplots under 1 column\n",
        "\n",
        "#Assigning the first subplot to graph training loss and validation loss\n",
        "ax[0].plot(AlexNet.history.history['loss'],color='b',label='Training Loss')\n",
        "ax[0].plot(AlexNet.history.history['val_loss'],color='r',label='Validation Loss')\n",
        "\n",
        "#Plotting the training accuracy and validation accuracy\n",
        "ax[1].plot(AlexNet.history.history['accuracy'],color='b',label='Training  Accuracy')\n",
        "ax[1].plot(AlexNet.history.history['val_accuracy'],color='r',label='Validation Accuracy')\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}